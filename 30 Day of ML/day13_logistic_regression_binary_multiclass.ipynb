{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Day 13: Logistic Regression â€“ Binary & Multiclass Classification\n",
    "\n",
    "## ðŸ“Œ Overview\n",
    "Logistic Regression is a popular classification algorithm used for binary and multiclass classification problems. Unlike Linear Regression, it predicts probabilities and uses sigmoid/softmax functions to output values between 0 and 1.\n",
    "\n",
    "\n",
    "## âœ… Binary Classification Example:\n",
    "- Dataset: Breast Cancer Dataset (Malignant/Benign)\n",
    "- Splitting data using train_test_split\n",
    "- Logistic Regression model fitting\n",
    "- Accuracy and Classification Report\n",
    "\n",
    "### Code Output Example:\n",
    "```\n",
    "Accuracy Score: 0.956140350877193\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.96      0.96      0.96        42\n",
    "           1       0.95      0.95      0.95        72\n",
    "\n",
    "    accuracy                           0.96       114\n",
    "   macro avg       0.96      0.96      0.96       114\n",
    "weighted avg       0.96      0.96      0.96       114\n",
    "```\n",
    "\n",
    "\n",
    "## âœ… Multiclass Classification Example:\n",
    "- Dataset: Iris Dataset (3 classes)\n",
    "- Using multinomial Logistic Regression\n",
    "- Accuracy and Classification Report\n",
    "\n",
    "### Code Output Example:\n",
    "```\n",
    "Accuracy Score: 1.0\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    setosa       1.00      1.00      1.00        10\n",
    "versicolor       1.00      1.00      1.00         9\n",
    " virginica       1.00      1.00      1.00        11\n",
    "\n",
    "    accuracy                           1.00        30\n",
    "   macro avg       1.00      1.00      1.00        30\n",
    "weighted avg       1.00      1.00      1.00        30\n",
    "```\n",
    "\n",
    "\n",
    "## ðŸ“ˆ Insights:\n",
    "- Logistic Regression is powerful for simple classification tasks.\n",
    "- Binary classification uses sigmoid function.\n",
    "- Multiclass classification uses softmax (multinomial).\n",
    "- Easy to implement and interpret.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# ðŸ“„ logistic_regression_binary\n",
    "\n",
    "**âœ… Logistic Regression - Binary Classification Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset (Example: Breast Cancer Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset (Example: Breast Cancer Dataset)\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Matrix and Target Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Matrix and Target Vector\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target  # Binary target (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean radius",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean texture",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean perimeter",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean area",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean smoothness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean compactness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean concavity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean concave points",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean symmetry",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean fractal dimension",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "radius error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "texture error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "perimeter error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "area error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smoothness error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "compactness error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "concavity error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "concave points error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "symmetry error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fractal dimension error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst radius",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst texture",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst perimeter",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst area",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst smoothness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst compactness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst concavity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst concave points",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst symmetry",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst fractal dimension",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "461f1f17-04e0-451a-a76e-921c98227e59",
       "rows": [
        [
         "0",
         "17.99",
         "10.38",
         "122.8",
         "1001.0",
         "0.1184",
         "0.2776",
         "0.3001",
         "0.1471",
         "0.2419",
         "0.07871",
         "1.095",
         "0.9053",
         "8.589",
         "153.4",
         "0.006399",
         "0.04904",
         "0.05373",
         "0.01587",
         "0.03003",
         "0.006193",
         "25.38",
         "17.33",
         "184.6",
         "2019.0",
         "0.1622",
         "0.6656",
         "0.7119",
         "0.2654",
         "0.4601",
         "0.1189"
        ],
        [
         "1",
         "20.57",
         "17.77",
         "132.9",
         "1326.0",
         "0.08474",
         "0.07864",
         "0.0869",
         "0.07017",
         "0.1812",
         "0.05667",
         "0.5435",
         "0.7339",
         "3.398",
         "74.08",
         "0.005225",
         "0.01308",
         "0.0186",
         "0.0134",
         "0.01389",
         "0.003532",
         "24.99",
         "23.41",
         "158.8",
         "1956.0",
         "0.1238",
         "0.1866",
         "0.2416",
         "0.186",
         "0.275",
         "0.08902"
        ],
        [
         "2",
         "19.69",
         "21.25",
         "130.0",
         "1203.0",
         "0.1096",
         "0.1599",
         "0.1974",
         "0.1279",
         "0.2069",
         "0.05999",
         "0.7456",
         "0.7869",
         "4.585",
         "94.03",
         "0.00615",
         "0.04006",
         "0.03832",
         "0.02058",
         "0.0225",
         "0.004571",
         "23.57",
         "25.53",
         "152.5",
         "1709.0",
         "0.1444",
         "0.4245",
         "0.4504",
         "0.243",
         "0.3613",
         "0.08758"
        ],
        [
         "3",
         "11.42",
         "20.38",
         "77.58",
         "386.1",
         "0.1425",
         "0.2839",
         "0.2414",
         "0.1052",
         "0.2597",
         "0.09744",
         "0.4956",
         "1.156",
         "3.445",
         "27.23",
         "0.00911",
         "0.07458",
         "0.05661",
         "0.01867",
         "0.05963",
         "0.009208",
         "14.91",
         "26.5",
         "98.87",
         "567.7",
         "0.2098",
         "0.8663",
         "0.6869",
         "0.2575",
         "0.6638",
         "0.173"
        ],
        [
         "4",
         "20.29",
         "14.34",
         "135.1",
         "1297.0",
         "0.1003",
         "0.1328",
         "0.198",
         "0.1043",
         "0.1809",
         "0.05883",
         "0.7572",
         "0.7813",
         "5.438",
         "94.44",
         "0.01149",
         "0.02461",
         "0.05688",
         "0.01885",
         "0.01756",
         "0.005115",
         "22.54",
         "16.67",
         "152.2",
         "1575.0",
         "0.1374",
         "0.205",
         "0.4",
         "0.1625",
         "0.2364",
         "0.07678"
        ],
        [
         "5",
         "12.45",
         "15.7",
         "82.57",
         "477.1",
         "0.1278",
         "0.17",
         "0.1578",
         "0.08089",
         "0.2087",
         "0.07613",
         "0.3345",
         "0.8902",
         "2.217",
         "27.19",
         "0.00751",
         "0.03345",
         "0.03672",
         "0.01137",
         "0.02165",
         "0.005082",
         "15.47",
         "23.75",
         "103.4",
         "741.6",
         "0.1791",
         "0.5249",
         "0.5355",
         "0.1741",
         "0.3985",
         "0.1244"
        ],
        [
         "6",
         "18.25",
         "19.98",
         "119.6",
         "1040.0",
         "0.09463",
         "0.109",
         "0.1127",
         "0.074",
         "0.1794",
         "0.05742",
         "0.4467",
         "0.7732",
         "3.18",
         "53.91",
         "0.004314",
         "0.01382",
         "0.02254",
         "0.01039",
         "0.01369",
         "0.002179",
         "22.88",
         "27.66",
         "153.2",
         "1606.0",
         "0.1442",
         "0.2576",
         "0.3784",
         "0.1932",
         "0.3063",
         "0.08368"
        ],
        [
         "7",
         "13.71",
         "20.83",
         "90.2",
         "577.9",
         "0.1189",
         "0.1645",
         "0.09366",
         "0.05985",
         "0.2196",
         "0.07451",
         "0.5835",
         "1.377",
         "3.856",
         "50.96",
         "0.008805",
         "0.03029",
         "0.02488",
         "0.01448",
         "0.01486",
         "0.005412",
         "17.06",
         "28.14",
         "110.6",
         "897.0",
         "0.1654",
         "0.3682",
         "0.2678",
         "0.1556",
         "0.3196",
         "0.1151"
        ],
        [
         "8",
         "13.0",
         "21.82",
         "87.5",
         "519.8",
         "0.1273",
         "0.1932",
         "0.1859",
         "0.09353",
         "0.235",
         "0.07389",
         "0.3063",
         "1.002",
         "2.406",
         "24.32",
         "0.005731",
         "0.03502",
         "0.03553",
         "0.01226",
         "0.02143",
         "0.003749",
         "15.49",
         "30.73",
         "106.2",
         "739.3",
         "0.1703",
         "0.5401",
         "0.539",
         "0.206",
         "0.4378",
         "0.1072"
        ],
        [
         "9",
         "12.46",
         "24.04",
         "83.97",
         "475.9",
         "0.1186",
         "0.2396",
         "0.2273",
         "0.08543",
         "0.203",
         "0.08243",
         "0.2976",
         "1.599",
         "2.039",
         "23.94",
         "0.007149",
         "0.07217",
         "0.07743",
         "0.01432",
         "0.01789",
         "0.01008",
         "15.09",
         "40.68",
         "97.65",
         "711.4",
         "0.1853",
         "1.058",
         "1.105",
         "0.221",
         "0.4366",
         "0.2075"
        ],
        [
         "10",
         "16.02",
         "23.24",
         "102.7",
         "797.8",
         "0.08206",
         "0.06669",
         "0.03299",
         "0.03323",
         "0.1528",
         "0.05697",
         "0.3795",
         "1.187",
         "2.466",
         "40.51",
         "0.004029",
         "0.009269",
         "0.01101",
         "0.007591",
         "0.0146",
         "0.003042",
         "19.19",
         "33.88",
         "123.8",
         "1150.0",
         "0.1181",
         "0.1551",
         "0.1459",
         "0.09975",
         "0.2948",
         "0.08452"
        ],
        [
         "11",
         "15.78",
         "17.89",
         "103.6",
         "781.0",
         "0.0971",
         "0.1292",
         "0.09954",
         "0.06606",
         "0.1842",
         "0.06082",
         "0.5058",
         "0.9849",
         "3.564",
         "54.16",
         "0.005771",
         "0.04061",
         "0.02791",
         "0.01282",
         "0.02008",
         "0.004144",
         "20.42",
         "27.28",
         "136.5",
         "1299.0",
         "0.1396",
         "0.5609",
         "0.3965",
         "0.181",
         "0.3792",
         "0.1048"
        ],
        [
         "12",
         "19.17",
         "24.8",
         "132.4",
         "1123.0",
         "0.0974",
         "0.2458",
         "0.2065",
         "0.1118",
         "0.2397",
         "0.078",
         "0.9555",
         "3.568",
         "11.07",
         "116.2",
         "0.003139",
         "0.08297",
         "0.0889",
         "0.0409",
         "0.04484",
         "0.01284",
         "20.96",
         "29.94",
         "151.7",
         "1332.0",
         "0.1037",
         "0.3903",
         "0.3639",
         "0.1767",
         "0.3176",
         "0.1023"
        ],
        [
         "13",
         "15.85",
         "23.95",
         "103.7",
         "782.7",
         "0.08401",
         "0.1002",
         "0.09938",
         "0.05364",
         "0.1847",
         "0.05338",
         "0.4033",
         "1.078",
         "2.903",
         "36.58",
         "0.009769",
         "0.03126",
         "0.05051",
         "0.01992",
         "0.02981",
         "0.003002",
         "16.84",
         "27.66",
         "112.0",
         "876.5",
         "0.1131",
         "0.1924",
         "0.2322",
         "0.1119",
         "0.2809",
         "0.06287"
        ],
        [
         "14",
         "13.73",
         "22.61",
         "93.6",
         "578.3",
         "0.1131",
         "0.2293",
         "0.2128",
         "0.08025",
         "0.2069",
         "0.07682",
         "0.2121",
         "1.169",
         "2.061",
         "19.21",
         "0.006429",
         "0.05936",
         "0.05501",
         "0.01628",
         "0.01961",
         "0.008093",
         "15.03",
         "32.01",
         "108.8",
         "697.7",
         "0.1651",
         "0.7725",
         "0.6943",
         "0.2208",
         "0.3596",
         "0.1431"
        ],
        [
         "15",
         "14.54",
         "27.54",
         "96.73",
         "658.8",
         "0.1139",
         "0.1595",
         "0.1639",
         "0.07364",
         "0.2303",
         "0.07077",
         "0.37",
         "1.033",
         "2.879",
         "32.55",
         "0.005607",
         "0.0424",
         "0.04741",
         "0.0109",
         "0.01857",
         "0.005466",
         "17.46",
         "37.13",
         "124.1",
         "943.2",
         "0.1678",
         "0.6577",
         "0.7026",
         "0.1712",
         "0.4218",
         "0.1341"
        ],
        [
         "16",
         "14.68",
         "20.13",
         "94.74",
         "684.5",
         "0.09867",
         "0.072",
         "0.07395",
         "0.05259",
         "0.1586",
         "0.05922",
         "0.4727",
         "1.24",
         "3.195",
         "45.4",
         "0.005718",
         "0.01162",
         "0.01998",
         "0.01109",
         "0.0141",
         "0.002085",
         "19.07",
         "30.88",
         "123.4",
         "1138.0",
         "0.1464",
         "0.1871",
         "0.2914",
         "0.1609",
         "0.3029",
         "0.08216"
        ],
        [
         "17",
         "16.13",
         "20.68",
         "108.1",
         "798.8",
         "0.117",
         "0.2022",
         "0.1722",
         "0.1028",
         "0.2164",
         "0.07356",
         "0.5692",
         "1.073",
         "3.854",
         "54.18",
         "0.007026",
         "0.02501",
         "0.03188",
         "0.01297",
         "0.01689",
         "0.004142",
         "20.96",
         "31.48",
         "136.8",
         "1315.0",
         "0.1789",
         "0.4233",
         "0.4784",
         "0.2073",
         "0.3706",
         "0.1142"
        ],
        [
         "18",
         "19.81",
         "22.15",
         "130.0",
         "1260.0",
         "0.09831",
         "0.1027",
         "0.1479",
         "0.09498",
         "0.1582",
         "0.05395",
         "0.7582",
         "1.017",
         "5.865",
         "112.4",
         "0.006494",
         "0.01893",
         "0.03391",
         "0.01521",
         "0.01356",
         "0.001997",
         "27.32",
         "30.88",
         "186.8",
         "2398.0",
         "0.1512",
         "0.315",
         "0.5372",
         "0.2388",
         "0.2768",
         "0.07615"
        ],
        [
         "19",
         "13.54",
         "14.36",
         "87.46",
         "566.3",
         "0.09779",
         "0.08129",
         "0.06664",
         "0.04781",
         "0.1885",
         "0.05766",
         "0.2699",
         "0.7886",
         "2.058",
         "23.56",
         "0.008462",
         "0.0146",
         "0.02387",
         "0.01315",
         "0.0198",
         "0.0023",
         "15.11",
         "19.26",
         "99.7",
         "711.2",
         "0.144",
         "0.1773",
         "0.239",
         "0.1288",
         "0.2977",
         "0.07259"
        ],
        [
         "20",
         "13.08",
         "15.71",
         "85.63",
         "520.0",
         "0.1075",
         "0.127",
         "0.04568",
         "0.0311",
         "0.1967",
         "0.06811",
         "0.1852",
         "0.7477",
         "1.383",
         "14.67",
         "0.004097",
         "0.01898",
         "0.01698",
         "0.00649",
         "0.01678",
         "0.002425",
         "14.5",
         "20.49",
         "96.09",
         "630.5",
         "0.1312",
         "0.2776",
         "0.189",
         "0.07283",
         "0.3184",
         "0.08183"
        ],
        [
         "21",
         "9.504",
         "12.44",
         "60.34",
         "273.9",
         "0.1024",
         "0.06492",
         "0.02956",
         "0.02076",
         "0.1815",
         "0.06905",
         "0.2773",
         "0.9768",
         "1.909",
         "15.7",
         "0.009606",
         "0.01432",
         "0.01985",
         "0.01421",
         "0.02027",
         "0.002968",
         "10.23",
         "15.66",
         "65.13",
         "314.9",
         "0.1324",
         "0.1148",
         "0.08867",
         "0.06227",
         "0.245",
         "0.07773"
        ],
        [
         "22",
         "15.34",
         "14.26",
         "102.5",
         "704.4",
         "0.1073",
         "0.2135",
         "0.2077",
         "0.09756",
         "0.2521",
         "0.07032",
         "0.4388",
         "0.7096",
         "3.384",
         "44.91",
         "0.006789",
         "0.05328",
         "0.06446",
         "0.02252",
         "0.03672",
         "0.004394",
         "18.07",
         "19.08",
         "125.1",
         "980.9",
         "0.139",
         "0.5954",
         "0.6305",
         "0.2393",
         "0.4667",
         "0.09946"
        ],
        [
         "23",
         "21.16",
         "23.04",
         "137.2",
         "1404.0",
         "0.09428",
         "0.1022",
         "0.1097",
         "0.08632",
         "0.1769",
         "0.05278",
         "0.6917",
         "1.127",
         "4.303",
         "93.99",
         "0.004728",
         "0.01259",
         "0.01715",
         "0.01038",
         "0.01083",
         "0.001987",
         "29.17",
         "35.59",
         "188.0",
         "2615.0",
         "0.1401",
         "0.26",
         "0.3155",
         "0.2009",
         "0.2822",
         "0.07526"
        ],
        [
         "24",
         "16.65",
         "21.38",
         "110.0",
         "904.6",
         "0.1121",
         "0.1457",
         "0.1525",
         "0.0917",
         "0.1995",
         "0.0633",
         "0.8068",
         "0.9017",
         "5.455",
         "102.6",
         "0.006048",
         "0.01882",
         "0.02741",
         "0.0113",
         "0.01468",
         "0.002801",
         "26.46",
         "31.56",
         "177.0",
         "2215.0",
         "0.1805",
         "0.3578",
         "0.4695",
         "0.2095",
         "0.3613",
         "0.09564"
        ],
        [
         "25",
         "17.14",
         "16.4",
         "116.0",
         "912.7",
         "0.1186",
         "0.2276",
         "0.2229",
         "0.1401",
         "0.304",
         "0.07413",
         "1.046",
         "0.976",
         "7.276",
         "111.4",
         "0.008029",
         "0.03799",
         "0.03732",
         "0.02397",
         "0.02308",
         "0.007444",
         "22.25",
         "21.4",
         "152.4",
         "1461.0",
         "0.1545",
         "0.3949",
         "0.3853",
         "0.255",
         "0.4066",
         "0.1059"
        ],
        [
         "26",
         "14.58",
         "21.53",
         "97.41",
         "644.8",
         "0.1054",
         "0.1868",
         "0.1425",
         "0.08783",
         "0.2252",
         "0.06924",
         "0.2545",
         "0.9832",
         "2.11",
         "21.05",
         "0.004452",
         "0.03055",
         "0.02681",
         "0.01352",
         "0.01454",
         "0.003711",
         "17.62",
         "33.21",
         "122.4",
         "896.9",
         "0.1525",
         "0.6643",
         "0.5539",
         "0.2701",
         "0.4264",
         "0.1275"
        ],
        [
         "27",
         "18.61",
         "20.25",
         "122.1",
         "1094.0",
         "0.0944",
         "0.1066",
         "0.149",
         "0.07731",
         "0.1697",
         "0.05699",
         "0.8529",
         "1.849",
         "5.632",
         "93.54",
         "0.01075",
         "0.02722",
         "0.05081",
         "0.01911",
         "0.02293",
         "0.004217",
         "21.31",
         "27.26",
         "139.9",
         "1403.0",
         "0.1338",
         "0.2117",
         "0.3446",
         "0.149",
         "0.2341",
         "0.07421"
        ],
        [
         "28",
         "15.3",
         "25.27",
         "102.4",
         "732.4",
         "0.1082",
         "0.1697",
         "0.1683",
         "0.08751",
         "0.1926",
         "0.0654",
         "0.439",
         "1.012",
         "3.498",
         "43.5",
         "0.005233",
         "0.03057",
         "0.03576",
         "0.01083",
         "0.01768",
         "0.002967",
         "20.27",
         "36.71",
         "149.3",
         "1269.0",
         "0.1641",
         "0.611",
         "0.6335",
         "0.2024",
         "0.4027",
         "0.09876"
        ],
        [
         "29",
         "17.57",
         "15.05",
         "115.0",
         "955.1",
         "0.09847",
         "0.1157",
         "0.09875",
         "0.07953",
         "0.1739",
         "0.06149",
         "0.6003",
         "0.8225",
         "4.655",
         "61.1",
         "0.005627",
         "0.03033",
         "0.03407",
         "0.01354",
         "0.01925",
         "0.003742",
         "20.01",
         "19.52",
         "134.9",
         "1227.0",
         "0.1255",
         "0.2812",
         "0.2489",
         "0.1456",
         "0.2756",
         "0.07919"
        ],
        [
         "30",
         "18.63",
         "25.11",
         "124.8",
         "1088.0",
         "0.1064",
         "0.1887",
         "0.2319",
         "0.1244",
         "0.2183",
         "0.06197",
         "0.8307",
         "1.466",
         "5.574",
         "105.0",
         "0.006248",
         "0.03374",
         "0.05196",
         "0.01158",
         "0.02007",
         "0.00456",
         "23.15",
         "34.01",
         "160.5",
         "1670.0",
         "0.1491",
         "0.4257",
         "0.6133",
         "0.1848",
         "0.3444",
         "0.09782"
        ],
        [
         "31",
         "11.84",
         "18.7",
         "77.93",
         "440.6",
         "0.1109",
         "0.1516",
         "0.1218",
         "0.05182",
         "0.2301",
         "0.07799",
         "0.4825",
         "1.03",
         "3.475",
         "41.0",
         "0.005551",
         "0.03414",
         "0.04205",
         "0.01044",
         "0.02273",
         "0.005667",
         "16.82",
         "28.12",
         "119.4",
         "888.7",
         "0.1637",
         "0.5775",
         "0.6956",
         "0.1546",
         "0.4761",
         "0.1402"
        ],
        [
         "32",
         "17.02",
         "23.98",
         "112.8",
         "899.3",
         "0.1197",
         "0.1496",
         "0.2417",
         "0.1203",
         "0.2248",
         "0.06382",
         "0.6009",
         "1.398",
         "3.999",
         "67.78",
         "0.008268",
         "0.03082",
         "0.05042",
         "0.01112",
         "0.02102",
         "0.003854",
         "20.88",
         "32.09",
         "136.1",
         "1344.0",
         "0.1634",
         "0.3559",
         "0.5588",
         "0.1847",
         "0.353",
         "0.08482"
        ],
        [
         "33",
         "19.27",
         "26.47",
         "127.9",
         "1162.0",
         "0.09401",
         "0.1719",
         "0.1657",
         "0.07593",
         "0.1853",
         "0.06261",
         "0.5558",
         "0.6062",
         "3.528",
         "68.17",
         "0.005015",
         "0.03318",
         "0.03497",
         "0.009643",
         "0.01543",
         "0.003896",
         "24.15",
         "30.9",
         "161.4",
         "1813.0",
         "0.1509",
         "0.659",
         "0.6091",
         "0.1785",
         "0.3672",
         "0.1123"
        ],
        [
         "34",
         "16.13",
         "17.88",
         "107.0",
         "807.2",
         "0.104",
         "0.1559",
         "0.1354",
         "0.07752",
         "0.1998",
         "0.06515",
         "0.334",
         "0.6857",
         "2.183",
         "35.03",
         "0.004185",
         "0.02868",
         "0.02664",
         "0.009067",
         "0.01703",
         "0.003817",
         "20.21",
         "27.26",
         "132.7",
         "1261.0",
         "0.1446",
         "0.5804",
         "0.5274",
         "0.1864",
         "0.427",
         "0.1233"
        ],
        [
         "35",
         "16.74",
         "21.59",
         "110.1",
         "869.5",
         "0.0961",
         "0.1336",
         "0.1348",
         "0.06018",
         "0.1896",
         "0.05656",
         "0.4615",
         "0.9197",
         "3.008",
         "45.19",
         "0.005776",
         "0.02499",
         "0.03695",
         "0.01195",
         "0.02789",
         "0.002665",
         "20.01",
         "29.02",
         "133.5",
         "1229.0",
         "0.1563",
         "0.3835",
         "0.5409",
         "0.1813",
         "0.4863",
         "0.08633"
        ],
        [
         "36",
         "14.25",
         "21.72",
         "93.63",
         "633.0",
         "0.09823",
         "0.1098",
         "0.1319",
         "0.05598",
         "0.1885",
         "0.06125",
         "0.286",
         "1.019",
         "2.657",
         "24.91",
         "0.005878",
         "0.02995",
         "0.04815",
         "0.01161",
         "0.02028",
         "0.004022",
         "15.89",
         "30.36",
         "116.2",
         "799.6",
         "0.1446",
         "0.4238",
         "0.5186",
         "0.1447",
         "0.3591",
         "0.1014"
        ],
        [
         "37",
         "13.03",
         "18.42",
         "82.61",
         "523.8",
         "0.08983",
         "0.03766",
         "0.02562",
         "0.02923",
         "0.1467",
         "0.05863",
         "0.1839",
         "2.342",
         "1.17",
         "14.16",
         "0.004352",
         "0.004899",
         "0.01343",
         "0.01164",
         "0.02671",
         "0.001777",
         "13.3",
         "22.81",
         "84.46",
         "545.9",
         "0.09701",
         "0.04619",
         "0.04833",
         "0.05013",
         "0.1987",
         "0.06169"
        ],
        [
         "38",
         "14.99",
         "25.2",
         "95.54",
         "698.8",
         "0.09387",
         "0.05131",
         "0.02398",
         "0.02899",
         "0.1565",
         "0.05504",
         "1.214",
         "2.188",
         "8.077",
         "106.0",
         "0.006883",
         "0.01094",
         "0.01818",
         "0.01917",
         "0.007882",
         "0.001754",
         "14.99",
         "25.2",
         "95.54",
         "698.8",
         "0.09387",
         "0.05131",
         "0.02398",
         "0.02899",
         "0.1565",
         "0.05504"
        ],
        [
         "39",
         "13.48",
         "20.82",
         "88.4",
         "559.2",
         "0.1016",
         "0.1255",
         "0.1063",
         "0.05439",
         "0.172",
         "0.06419",
         "0.213",
         "0.5914",
         "1.545",
         "18.52",
         "0.005367",
         "0.02239",
         "0.03049",
         "0.01262",
         "0.01377",
         "0.003187",
         "15.53",
         "26.02",
         "107.3",
         "740.4",
         "0.161",
         "0.4225",
         "0.503",
         "0.2258",
         "0.2807",
         "0.1071"
        ],
        [
         "40",
         "13.44",
         "21.58",
         "86.18",
         "563.0",
         "0.08162",
         "0.06031",
         "0.0311",
         "0.02031",
         "0.1784",
         "0.05587",
         "0.2385",
         "0.8265",
         "1.572",
         "20.53",
         "0.00328",
         "0.01102",
         "0.0139",
         "0.006881",
         "0.0138",
         "0.001286",
         "15.93",
         "30.25",
         "102.5",
         "787.9",
         "0.1094",
         "0.2043",
         "0.2085",
         "0.1112",
         "0.2994",
         "0.07146"
        ],
        [
         "41",
         "10.95",
         "21.35",
         "71.9",
         "371.1",
         "0.1227",
         "0.1218",
         "0.1044",
         "0.05669",
         "0.1895",
         "0.0687",
         "0.2366",
         "1.428",
         "1.822",
         "16.97",
         "0.008064",
         "0.01764",
         "0.02595",
         "0.01037",
         "0.01357",
         "0.00304",
         "12.84",
         "35.34",
         "87.22",
         "514.0",
         "0.1909",
         "0.2698",
         "0.4023",
         "0.1424",
         "0.2964",
         "0.09606"
        ],
        [
         "42",
         "19.07",
         "24.81",
         "128.3",
         "1104.0",
         "0.09081",
         "0.219",
         "0.2107",
         "0.09961",
         "0.231",
         "0.06343",
         "0.9811",
         "1.666",
         "8.83",
         "104.9",
         "0.006548",
         "0.1006",
         "0.09723",
         "0.02638",
         "0.05333",
         "0.007646",
         "24.09",
         "33.17",
         "177.4",
         "1651.0",
         "0.1247",
         "0.7444",
         "0.7242",
         "0.2493",
         "0.467",
         "0.1038"
        ],
        [
         "43",
         "13.28",
         "20.28",
         "87.32",
         "545.2",
         "0.1041",
         "0.1436",
         "0.09847",
         "0.06158",
         "0.1974",
         "0.06782",
         "0.3704",
         "0.8249",
         "2.427",
         "31.33",
         "0.005072",
         "0.02147",
         "0.02185",
         "0.00956",
         "0.01719",
         "0.003317",
         "17.38",
         "28.0",
         "113.1",
         "907.2",
         "0.153",
         "0.3724",
         "0.3664",
         "0.1492",
         "0.3739",
         "0.1027"
        ],
        [
         "44",
         "13.17",
         "21.81",
         "85.42",
         "531.5",
         "0.09714",
         "0.1047",
         "0.08259",
         "0.05252",
         "0.1746",
         "0.06177",
         "0.1938",
         "0.6123",
         "1.334",
         "14.49",
         "0.00335",
         "0.01384",
         "0.01452",
         "0.006853",
         "0.01113",
         "0.00172",
         "16.23",
         "29.89",
         "105.5",
         "740.7",
         "0.1503",
         "0.3904",
         "0.3728",
         "0.1607",
         "0.3693",
         "0.09618"
        ],
        [
         "45",
         "18.65",
         "17.6",
         "123.7",
         "1076.0",
         "0.1099",
         "0.1686",
         "0.1974",
         "0.1009",
         "0.1907",
         "0.06049",
         "0.6289",
         "0.6633",
         "4.293",
         "71.56",
         "0.006294",
         "0.03994",
         "0.05554",
         "0.01695",
         "0.02428",
         "0.003535",
         "22.82",
         "21.32",
         "150.6",
         "1567.0",
         "0.1679",
         "0.509",
         "0.7345",
         "0.2378",
         "0.3799",
         "0.09185"
        ],
        [
         "46",
         "8.196",
         "16.84",
         "51.71",
         "201.9",
         "0.086",
         "0.05943",
         "0.01588",
         "0.005917",
         "0.1769",
         "0.06503",
         "0.1563",
         "0.9567",
         "1.094",
         "8.205",
         "0.008968",
         "0.01646",
         "0.01588",
         "0.005917",
         "0.02574",
         "0.002582",
         "8.964",
         "21.96",
         "57.26",
         "242.2",
         "0.1297",
         "0.1357",
         "0.0688",
         "0.02564",
         "0.3105",
         "0.07409"
        ],
        [
         "47",
         "13.17",
         "18.66",
         "85.98",
         "534.6",
         "0.1158",
         "0.1231",
         "0.1226",
         "0.0734",
         "0.2128",
         "0.06777",
         "0.2871",
         "0.8937",
         "1.897",
         "24.25",
         "0.006532",
         "0.02336",
         "0.02905",
         "0.01215",
         "0.01743",
         "0.003643",
         "15.67",
         "27.95",
         "102.8",
         "759.4",
         "0.1786",
         "0.4166",
         "0.5006",
         "0.2088",
         "0.39",
         "0.1179"
        ],
        [
         "48",
         "12.05",
         "14.63",
         "78.04",
         "449.3",
         "0.1031",
         "0.09092",
         "0.06592",
         "0.02749",
         "0.1675",
         "0.06043",
         "0.2636",
         "0.7294",
         "1.848",
         "19.87",
         "0.005488",
         "0.01427",
         "0.02322",
         "0.00566",
         "0.01428",
         "0.002422",
         "13.76",
         "20.7",
         "89.88",
         "582.6",
         "0.1494",
         "0.2156",
         "0.305",
         "0.06548",
         "0.2747",
         "0.08301"
        ],
        [
         "49",
         "13.49",
         "22.3",
         "86.91",
         "561.0",
         "0.08752",
         "0.07698",
         "0.04751",
         "0.03384",
         "0.1809",
         "0.05718",
         "0.2338",
         "1.353",
         "1.735",
         "20.2",
         "0.004455",
         "0.01382",
         "0.02095",
         "0.01184",
         "0.01641",
         "0.001956",
         "15.15",
         "31.82",
         "99.0",
         "698.8",
         "0.1162",
         "0.1711",
         "0.2282",
         "0.1282",
         "0.2871",
         "0.06917"
        ]
       ],
       "shape": {
        "columns": 30,
        "rows": 569
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=200)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binary Classification Results:\n",
      "Accuracy Score: 0.956140350877193\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        43\n",
      "           1       0.95      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print(\"\\nBinary Classification Results:\")\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“„ logistic_regression_multiclass\n",
    "\n",
    "**âœ… Logistic Regression - Multiclass Classification Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset (Example: Iris Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Matrix and Target Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target  # Multiclass target (0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sepal length (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sepal width (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "petal length (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "petal width (cm)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "34a7507d-bfb7-42f9-b64d-f382a823a426",
       "rows": [
        [
         "0",
         "5.1",
         "3.5",
         "1.4",
         "0.2"
        ],
        [
         "1",
         "4.9",
         "3.0",
         "1.4",
         "0.2"
        ],
        [
         "2",
         "4.7",
         "3.2",
         "1.3",
         "0.2"
        ],
        [
         "3",
         "4.6",
         "3.1",
         "1.5",
         "0.2"
        ],
        [
         "4",
         "5.0",
         "3.6",
         "1.4",
         "0.2"
        ],
        [
         "5",
         "5.4",
         "3.9",
         "1.7",
         "0.4"
        ],
        [
         "6",
         "4.6",
         "3.4",
         "1.4",
         "0.3"
        ],
        [
         "7",
         "5.0",
         "3.4",
         "1.5",
         "0.2"
        ],
        [
         "8",
         "4.4",
         "2.9",
         "1.4",
         "0.2"
        ],
        [
         "9",
         "4.9",
         "3.1",
         "1.5",
         "0.1"
        ],
        [
         "10",
         "5.4",
         "3.7",
         "1.5",
         "0.2"
        ],
        [
         "11",
         "4.8",
         "3.4",
         "1.6",
         "0.2"
        ],
        [
         "12",
         "4.8",
         "3.0",
         "1.4",
         "0.1"
        ],
        [
         "13",
         "4.3",
         "3.0",
         "1.1",
         "0.1"
        ],
        [
         "14",
         "5.8",
         "4.0",
         "1.2",
         "0.2"
        ],
        [
         "15",
         "5.7",
         "4.4",
         "1.5",
         "0.4"
        ],
        [
         "16",
         "5.4",
         "3.9",
         "1.3",
         "0.4"
        ],
        [
         "17",
         "5.1",
         "3.5",
         "1.4",
         "0.3"
        ],
        [
         "18",
         "5.7",
         "3.8",
         "1.7",
         "0.3"
        ],
        [
         "19",
         "5.1",
         "3.8",
         "1.5",
         "0.3"
        ],
        [
         "20",
         "5.4",
         "3.4",
         "1.7",
         "0.2"
        ],
        [
         "21",
         "5.1",
         "3.7",
         "1.5",
         "0.4"
        ],
        [
         "22",
         "4.6",
         "3.6",
         "1.0",
         "0.2"
        ],
        [
         "23",
         "5.1",
         "3.3",
         "1.7",
         "0.5"
        ],
        [
         "24",
         "4.8",
         "3.4",
         "1.9",
         "0.2"
        ],
        [
         "25",
         "5.0",
         "3.0",
         "1.6",
         "0.2"
        ],
        [
         "26",
         "5.0",
         "3.4",
         "1.6",
         "0.4"
        ],
        [
         "27",
         "5.2",
         "3.5",
         "1.5",
         "0.2"
        ],
        [
         "28",
         "5.2",
         "3.4",
         "1.4",
         "0.2"
        ],
        [
         "29",
         "4.7",
         "3.2",
         "1.6",
         "0.2"
        ],
        [
         "30",
         "4.8",
         "3.1",
         "1.6",
         "0.2"
        ],
        [
         "31",
         "5.4",
         "3.4",
         "1.5",
         "0.4"
        ],
        [
         "32",
         "5.2",
         "4.1",
         "1.5",
         "0.1"
        ],
        [
         "33",
         "5.5",
         "4.2",
         "1.4",
         "0.2"
        ],
        [
         "34",
         "4.9",
         "3.1",
         "1.5",
         "0.2"
        ],
        [
         "35",
         "5.0",
         "3.2",
         "1.2",
         "0.2"
        ],
        [
         "36",
         "5.5",
         "3.5",
         "1.3",
         "0.2"
        ],
        [
         "37",
         "4.9",
         "3.6",
         "1.4",
         "0.1"
        ],
        [
         "38",
         "4.4",
         "3.0",
         "1.3",
         "0.2"
        ],
        [
         "39",
         "5.1",
         "3.4",
         "1.5",
         "0.2"
        ],
        [
         "40",
         "5.0",
         "3.5",
         "1.3",
         "0.3"
        ],
        [
         "41",
         "4.5",
         "2.3",
         "1.3",
         "0.3"
        ],
        [
         "42",
         "4.4",
         "3.2",
         "1.3",
         "0.2"
        ],
        [
         "43",
         "5.0",
         "3.5",
         "1.6",
         "0.6"
        ],
        [
         "44",
         "5.1",
         "3.8",
         "1.9",
         "0.4"
        ],
        [
         "45",
         "4.8",
         "3.0",
         "1.4",
         "0.3"
        ],
        [
         "46",
         "5.1",
         "3.8",
         "1.6",
         "0.2"
        ],
        [
         "47",
         "4.6",
         "3.2",
         "1.4",
         "0.2"
        ],
        [
         "48",
         "5.3",
         "3.7",
         "1.5",
         "0.2"
        ],
        [
         "49",
         "5.0",
         "3.3",
         "1.4",
         "0.2"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 150
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model (Multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=200, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=200, multi_class=&#x27;multinomial&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=200, multi_class='multinomial')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=200)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiclass Classification Results:\n",
      "Accuracy Score: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMulticlass Classification Results:\")\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=data.target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
