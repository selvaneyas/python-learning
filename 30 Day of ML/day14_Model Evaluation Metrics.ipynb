{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 𝐃𝐚𝐲 𝟏𝟒: 𝐌𝐨𝐝𝐞𝐥 𝐄𝐯𝐚𝐥𝐮𝐚𝐭𝐢𝐨𝐧 𝐌𝐞𝐭𝐫𝐢𝐜𝐬 – 𝐌𝐀𝐄, 𝐌𝐒𝐄, 𝐑𝐌𝐒𝐄, 𝐀𝐜𝐜𝐮𝐫𝐚𝐜𝐲, 𝐏𝐫𝐞𝐜𝐢𝐬𝐢𝐨𝐧, 𝐑𝐞𝐜𝐚𝐥𝐥 | 𝟑𝟎-𝐃𝐚𝐲 𝐌𝐋 𝐂𝐡𝐚𝐥𝐥𝐞𝐧𝐠𝐞\n",
    "\n",
    "\n",
    "\n",
    "Evaluating a Machine Learning model is crucial to measure how well it performs on unseen data. Different problems require different evaluation metrics!\n",
    "\n",
    "\n",
    "\n",
    "## ✅𝐖𝐡𝐲 𝐌𝐨𝐝𝐞𝐥 𝐄𝐯𝐚𝐥𝐮𝐚𝐭𝐢𝐨𝐧 𝐢𝐬 𝐈𝐦𝐩𝐨𝐫𝐭𝐚𝐧𝐭?\n",
    "\n",
    "     🎯 Assess model's prediction quality\n",
    "\n",
    "     📈 Compare multiple models\n",
    "\n",
    "     🔁 Improve model performance through tuning\n",
    "\n",
    "\n",
    "\n",
    "## 🔑 𝐊𝐞𝐲 𝐄𝐯𝐚𝐥𝐮𝐚𝐭𝐢𝐨𝐧 𝐌𝐞𝐭𝐫𝐢𝐜𝐬:\n",
    "\n",
    "\n",
    "\n",
    "### 🔵 𝑭𝒐𝒓 𝑹𝒆𝒈𝒓𝒆𝒔𝒔𝒊𝒐𝒏 𝑷𝒓𝒐𝒃𝒍𝒆𝒎𝒔:\n",
    "\n",
    "1️⃣ 𝗠𝗔𝗘 (𝗠𝗲𝗮𝗻 𝗔𝗯𝘀𝗼𝗹𝘂𝘁𝗲 𝗘𝗿𝗿𝗼𝗿) – Average of absolute errors.\n",
    "\n",
    "     ➡️ Measures average magnitude of errors.\n",
    "\n",
    "2️⃣ 𝗠𝗦𝗘 (𝗠𝗲𝗮𝗻 𝗦𝗾𝘂𝗮𝗿𝗲𝗱 𝗘𝗿𝗿𝗼𝗿) – Average of squared errors.\n",
    "\n",
    "     ➡️ Penalizes larger errors more than smaller ones.\n",
    "\n",
    "3️⃣ 𝗥𝗠𝗦𝗘 (𝗥𝗼𝗼𝘁 𝗠𝗲𝗮𝗻 𝗦𝗾𝘂𝗮𝗿𝗲𝗱 𝗘𝗿𝗿𝗼𝗿) – Square root of MSE.\n",
    "\n",
    "     ➡️ Interpretable in same units as target variable.\n",
    "\n",
    "\n",
    "\n",
    "### 🟢 𝑭𝒐𝒓 𝑪𝒍𝒂𝒔𝒔𝒊𝒇𝒊𝒄𝒂𝒕𝒊𝒐𝒏 𝑷𝒓𝒐𝒃𝒍𝒆𝒎𝒔:\n",
    "\n",
    "4️⃣ 𝗔𝗰𝗰𝘂𝗿𝗮𝗰𝘆 – Proportion of correctly classified samples.\n",
    "\n",
    "      ➡️ Simple but can be misleading for imbalanced datasets.\n",
    "\n",
    "5️⃣ 𝗣𝗿𝗲𝗰𝗶𝘀𝗶𝗼𝗻 – True Positives / (True Positives + False Positives).\n",
    "\n",
    "      ➡️ How many predicted positives are actually positive.\n",
    "\n",
    "6️⃣ 𝗥𝗲𝗰𝗮𝗹𝗹 – True Positives / (True Positives + False Negatives).\n",
    "\n",
    "      ➡️ Ability to find all actual positives.\n",
    "\n",
    "\n",
    "\n",
    "## ✅ 𝑰𝒏𝒔𝒊𝒈𝒉𝒕𝒔:\n",
    "\n",
    "      📊 Use MAE, MSE, RMSE for regression to measure error magnitude.\n",
    "\n",
    "      🧠 Accuracy is good for balanced datasets, but Precision & Recall are better for imbalanced ones (like fraud detection, medical diagnosis).\n",
    "\n",
    "      🔍 Always choose metric based on business problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📄 regression_metrics (MAE, MSE, RMSE, R²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression metrics Example\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example actual and predicted values\n",
    "y_true = np.array([3, -0.5, 2, 7])\n",
    "y_pred = np.array([2.5, 0.0, 2, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error [MAE]: 0.500\n",
      "Mean Squared Error [MSE]: 0.375\n",
      "Root Mean Squared Error [RMSE]: 0.612\n",
      "R² Score: 0.949\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Absolute Error [MAE]: {mae:.3f}')\n",
    "print(f'Mean Squared Error [MSE]: {mse:.3f}')\n",
    "print(f'Root Mean Squared Error [RMSE]: {rmse:.3f}')\n",
    "print(f\"R² Score: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📄 classification_metrics (Accuracy, Precision, Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
